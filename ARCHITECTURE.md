ğŸ¤– STAN Chatbot â€“ Architecture Document

This document explains the system design, architecture, and workflow of the STAN Chatbot project.

ğŸ¯ Objectives

Create a human-like chatbot that can engage naturally.

Support long-term memory (remembers user preferences).

Adapt tone and context based on user input.

Ensure identity consistency and reduce hallucinations.

Work with a modular backend (FastAPI) and browser frontend.

ğŸ—ï¸ High-Level Architecture
-------------------------------------------------------------
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        Frontend        â”‚
                â”‚  (index.html, JS, CSS) â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚  (fetch API call)
                            â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        Backend         â”‚
                â”‚       (FastAPI)        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                 â–¼                 â–¼
   Memory Module        LLM Provider     Persona/Prompts


   
   
 -------------------------------------------------------------

ğŸ”¹ Components
1. Frontend (UI)

File: frontend/index.html

Technologies: HTML, CSS, Vanilla JS

Role: Provides a chat interface with text input and chat bubbles.

Function:

Captures user input.

Sends input to backend API (/chat).

Displays chatbot responses dynamically.

2. Backend (API Layer)

Framework: FastAPI (Python)

Entry point: backend/main.py

Responsibilities:

Expose a /chat endpoint.

Receive user messages + user ID.

Load previous conversation memory.

Build prompt with context + persona.

Call LLM Provider (e.g., Gemini API).

Save chatbot response + user message into SQLite memory.

Return the chatbot reply to the frontend.

3. Memory Module

File: backend/memory.py

Database: SQLite

Purpose: Store user interactions for long-term memory.

Structure:

userId (string)

role (user/assistant)

content (message text)

timestamp

Behavior:

On every chat, load the last 10â€“15 messages for context.

Recall user preferences (e.g., name, favorite color).

Maintain identity consistency across sessions.

4. LLM Provider

File: backend/llm_provider.py

Handles requests to Gemini API (gemini-2.5-flash) or other LLMs.

Wraps the API so it can be swapped easily with OpenAI, Claude, or local models (Mistral, Llama2).

Ensures cost efficiency by trimming context length.

5. Persona & Prompts

File: backend/prompts.py

Defines chatbot identity:

Name: Stan Pal

Role: Friendly, empathetic assistant.

Rules:

Stay consistent in personality.

Avoid hallucination (donâ€™t make up details).

Adapt tone based on user input (supportive if sad, playful if casual).

ğŸ”¹ Data Flow

User types a message in frontend UI.

JS fetch() sends the message to /chat API with userId.

Backend checks SQLite memory for past conversation.

Backend builds a prompt with persona + context.

LLM Provider sends the prompt to Gemini API.

Gemini API returns response â†’ backend saves it to memory.

Response sent back to frontend, displayed in chat UI.

ğŸ“¦ Scalability Considerations

Stateless backend â†’ conversation memory stored in DB, not RAM.

Can swap SQLite with Postgres, MongoDB, or Redis for production.

Supports multiple users (each has separate userId).

Modular design â†’ can integrate with UGC platforms (social media, forums, etc.).

ğŸ›¡ï¸ Hallucination Resistance

Bot is instructed to say:

â€œI donâ€™t remember that clearlyâ€ instead of inventing details.

Give vague but natural answers if asked impossible things.

ğŸ“– Example Scenario

User: â€œMy name is Channaâ€

Bot saves: {userId:1, key:name, value:"Channa"}

Laterâ€¦

User: â€œWhatâ€™s my name?â€

Bot recalls from memory â†’ â€œYou told me earlier your name is Channa ğŸ˜Šâ€

âš™ï¸ Tech Stack

Backend: FastAPI, Uvicorn, SQLite, SQLAlchemy

Frontend: HTML, CSS, JavaScript

LLM: Gemini API (gemini-2.5-flash)

Language: Python 3.10+





